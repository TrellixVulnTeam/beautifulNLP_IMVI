{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import operator\n",
    "\n",
    "class SimpleLogisticRegression(object):\n",
    "    def __init__(self, features_num):\n",
    "        self._m_features_num = features_num\n",
    "        self._m_weights = [1.0 / self._m_features_num] * self._m_features_num\n",
    "        self._m_bias = 1.0\n",
    "        \n",
    "        self._m_best_weights = [0.0] * self._m_features_num\n",
    "        self._m_best_bias = 0.0\n",
    "    \n",
    "    def _sigmoid(self, w, x, b):\n",
    "        return 1.0 / (1.0 + math.exp(-sum(map(operator.mul, w, x)) - b))\n",
    "    \n",
    "    def _likelihood(self, pred_y, y):\n",
    "        likelihood = 0.0\n",
    "        sample_num = 0\n",
    "        for py, ty in zip(pred_y, y):\n",
    "            likelihood += ty * math.log(py) + (1 - ty) * math.log(1 - py)\n",
    "            sample_num += 1\n",
    "        return likelihood / sample_num\n",
    "    \n",
    "    def fit(self, features, labels, learning_rate=0.1, epoches=10000):\n",
    "        sample_num = len(features)\n",
    "        best_likelihood, best_epoch = None, None\n",
    "        for epoch in range(epoches):\n",
    "            # 计算梯度\n",
    "            gradient = [0.] * (self._m_features_num + 1)\n",
    "            for tx, ty in zip(features, labels):\n",
    "                delta = ty - self._sigmoid(self._m_weights, tx, self._m_bias)\n",
    "                for i, xi in enumerate(tx):\n",
    "                    gradient[i] += delta * xi\n",
    "                gradient[-1] += delta\n",
    "            \n",
    "            # 更新参数\n",
    "            for i, grad in enumerate(gradient[:-1]):\n",
    "                self._m_weights[i] += learning_rate * grad / sample_num\n",
    "            self._m_bias += learning_rate * gradient[-1] / sample_num\n",
    "            \n",
    "            # 评估新模型\n",
    "            pred_y = [self._sigmoid(self._m_weights, x, self._m_bias) for x in features]\n",
    "            likelihood = self._likelihood(pred_y, labels)\n",
    "            if best_likelihood is None or likelihood - best_likelihood > 1e-8:\n",
    "                best_likelihood = likelihood\n",
    "                best_epoch = epoch\n",
    "                self._m_best_weights = self._m_weights[:]\n",
    "                self._m_best_bias = self._m_bias\n",
    "            elif epoch - best_epoch >= 10:\n",
    "                break;\n",
    "    \n",
    "    def predict(self, features):\n",
    "        return [self._sigmoid(self._m_best_weights, x, self._m_bias) for x in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004497222342978742, 0.018361156480988333, 0.983003700051452, 0.9999944082938986]\n"
     ]
    }
   ],
   "source": [
    "lr = SimpleLogisticRegression(3)\n",
    "features = [[1, 2, 3], [2, 4, 6], [3, 5, 7], [4, 6, 8]]\n",
    "labels = [0, 0, 1, 1]\n",
    "lr.fit(features, labels)\n",
    "print(lr.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
